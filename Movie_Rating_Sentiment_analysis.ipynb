{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "\n",
    "df_train = pd.read_csv(r\"C:\\Users\\manch\\OneDrive\\Desktop\\Data Science Live Course\\Movie Rating using Naive Bayes\\Dataset\\Train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\manch\\OneDrive\\Desktop\\Data Science Live Course\\Movie Rating using Naive Bayes\\Dataset\\Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "* Bag of words pipline\n",
    "    - Getting the corpus\n",
    "    - Tokenization\n",
    "    - Removing Stopwords\n",
    "    - Vectorization\n",
    "    - Building the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for NLT Preprocessing\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise the objects\n",
    "\n",
    "tokenizer = RegexpTokenizer(\"[a-zA-z0-9]+\")\n",
    "ps = PorterStemmer()\n",
    "en_stopwords = set(stopwords.words('English'))\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mature intelligent and highly charged melodram...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://video.google.com/videoplay?docid=211772...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Opera (1987) Director: Dario Argento Ca...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think a lot of people just wrote this off as...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a story of two dogs and a cat looking ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Steve Carell comes into his own in his first s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm only going to write more because it's requ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OK, it was a \"risky\" move to rent this flick, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cannibalism, a pair of cinematic references to...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is one of the great modern kung fu films....</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  mature intelligent and highly charged melodram...   pos\n",
       "1  http://video.google.com/videoplay?docid=211772...   pos\n",
       "2  Title: Opera (1987) Director: Dario Argento Ca...   pos\n",
       "3  I think a lot of people just wrote this off as...   pos\n",
       "4  This is a story of two dogs and a cat looking ...   pos\n",
       "5  Steve Carell comes into his own in his first s...   pos\n",
       "6  I'm only going to write more because it's requ...   neg\n",
       "7  OK, it was a \"risky\" move to rent this flick, ...   neg\n",
       "8  Cannibalism, a pair of cinematic references to...   pos\n",
       "9  This is one of the great modern kung fu films....   pos"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Getting the corpus\n",
    "\n",
    "df_train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['review'].values\n",
    "y = df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000,), (40000,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://video.google.com/videoplay?docid=211772166650071408&hl=en Distribution was tried.<br /><br />We opted for mass appeal.<br /><br />We want the best possible viewing range so, we forgo profit and continue our manual labor jobs gladly to entertain you for working yours.<br /><br />View Texas tale, please write about it... If you like it or not, if you like Alex or not, if you like Stuie, Texas or Texas tale... Just write about it.<br /><br />Your opinion rules.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Preprocessing\n",
    "def NLTK_preprocessing(review):\n",
    "    \n",
    "    words = []\n",
    "    for i in range(review.shape[0]):\n",
    "        # 2 Tokenization using Regular Expression\n",
    "        words.append(tokenizer.tokenize(review[i]))\n",
    "\n",
    "    useful_words = []\n",
    "    # 3 Remove stopwords\n",
    "    for i in range(len(words)):\n",
    "        useful_text = [w for w in words[i] if w not in en_stopwords]\n",
    "        useful_words.append(useful_text)\n",
    "    \n",
    "    # 4 Stemming\n",
    "    for i in range(len(useful_words)):\n",
    "        for j in range(len(useful_words[i])):\n",
    "            # Stem the words\n",
    "            useful_words[i][j] = ps.stem(useful_words[i][j])\n",
    "\n",
    "    # Join the words\n",
    "    for i in range(len(useful_words)):\n",
    "        useful_words[i] = \" \".join(useful_words[i])\n",
    "        \n",
    "    # 5 Vectorization\n",
    "    VectorizedCorpus = tfidf.fit_transform(useful_words)\n",
    "    \n",
    "    return VectorizedCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = NLTK_preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 64377)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 55639)\t0.07684381064085315\n",
      "  (0, 34560)\t0.15982311717744793\n",
      "  (0, 50061)\t0.058321332120231696\n",
      "  (0, 40990)\t0.3217183297518254\n",
      "  (0, 51579)\t0.11020267915811242\n",
      "  (0, 58050)\t0.1999433719427246\n",
      "  (0, 33856)\t0.07203606426840088\n",
      "  (0, 10173)\t0.3217183297518254\n",
      "  (0, 42767)\t0.0838985395420125\n",
      "  (0, 54449)\t0.29842737764167104\n",
      "  (0, 62016)\t0.5428362876041004\n",
      "  (0, 418)\t0.21900108687785186\n",
      "  (0, 11052)\t0.18262662783195674\n",
      "  (0, 20446)\t0.08967426547136485\n",
      "  (0, 59055)\t0.3217183297518254\n",
      "  (0, 36303)\t0.1741713963354127\n",
      "  (0, 10634)\t0.16107091134223578\n",
      "  (0, 26195)\t0.12278073628212646\n",
      "  (0, 28472)\t0.13171927796418542\n",
      "  (0, 35611)\t0.1688249625042704\n",
      "  (1, 48424)\t0.10938566763734439\n",
      "  (1, 40962)\t0.09125251511187199\n",
      "  (1, 63807)\t0.12270950248787452\n",
      "  (1, 30041)\t0.08825342761017835\n",
      "  (1, 54441)\t0.21788881926230955\n",
      "  :\t:\n",
      "  (39999, 49319)\t0.06557702422070845\n",
      "  (39999, 21948)\t0.08000096010890395\n",
      "  (39999, 26785)\t0.090170939690557\n",
      "  (39999, 42754)\t0.10051817181347081\n",
      "  (39999, 43641)\t0.06493123531046362\n",
      "  (39999, 61893)\t0.062137553707486255\n",
      "  (39999, 19089)\t0.054421884108247345\n",
      "  (39999, 3548)\t0.08785853465098603\n",
      "  (39999, 57057)\t0.04951218178557581\n",
      "  (39999, 54437)\t0.109200086512444\n",
      "  (39999, 12219)\t0.13476884696113312\n",
      "  (39999, 41084)\t0.08455287005809822\n",
      "  (39999, 46332)\t0.23092474728305012\n",
      "  (39999, 63159)\t0.05588154011100587\n",
      "  (39999, 21689)\t0.08574017147522313\n",
      "  (39999, 34699)\t0.05101885826513699\n",
      "  (39999, 23362)\t0.18354459739078655\n",
      "  (39999, 4821)\t0.08735321531336195\n",
      "  (39999, 50085)\t0.06659494300730133\n",
      "  (39999, 38143)\t0.11268635945561273\n",
      "  (39999, 56542)\t0.03493973060715962\n",
      "  (39999, 6494)\t0.06921393581436593\n",
      "  (39999, 61691)\t0.0679296501848455\n",
      "  (39999, 50061)\t0.15532402661364525\n",
      "  (39999, 33856)\t0.12789981706294523\n"
     ]
    }
   ],
   "source": [
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label Encode the target column\n",
    "def label_encoder(target_col):\n",
    "    \n",
    "    for i in range(target_col.shape[0]):\n",
    "        \n",
    "        # Encode the target columns: 1 for positive class and 0 for negative\n",
    "        if target_col[i] == 'pos':\n",
    "            \n",
    "            target_col[i] = 1\n",
    "        else:\n",
    "            \n",
    "            target_col[i] = 0\n",
    "    \n",
    "    return target_col.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_encoder(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Test_Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(vc, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28000, 64377), (28000,), (12000, 64377), (12000,))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "   * Multinomial Naive Bayes\n",
    "   * Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the object\n",
    "mnb = MultinomialNB()\n",
    "bnm = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Multinomial NB model\n",
    "\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "training_predictions = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score : [0.85957143 0.85985714 0.85142857 0.85057143]\n",
      "Precision Score :0.878735232800556\n",
      "Recall Score : 0.8354806739345887\n",
      "Confusion Matrix : [[5248  698]\n",
      " [ 996 5058]]\n"
     ]
    }
   ],
   "source": [
    "# Import Cross Validation score, Confusion matrix, precesion and recall\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "print(\"Cross Validation Score : \" + str(cross_val_score(mnb, X_train, y_train, cv = 4, scoring = \"accuracy\")))\n",
    "print(\"Precision Score :\" + str(precision_score(y_test, training_predictions)))\n",
    "print(\"Recall Score : \" + str(recall_score(y_test, training_predictions)))\n",
    "print(\"Confusion Matrix : \" + str(confusion_matrix(y_test, training_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Bernoulli NB model\n",
    "bnm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "training_predictions_bnm = bnm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score : [0.84785714 0.84528571 0.841      0.83542857]\n",
      "Precision Score :0.8761377833303587\n",
      "Recall Score : 0.8108688470432772\n",
      "Confusion Matrix : [[5252  694]\n",
      " [1145 4909]]\n"
     ]
    }
   ],
   "source": [
    "# Import Cross Validation score, Confusion matrix, precesion and recall\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "print(\"Cross Validation Score : \" + str(cross_val_score(bnm, X_train, y_train, cv = 4, scoring = \"accuracy\")))\n",
    "print(\"Precision Score :\" + str(precision_score(y_test, training_predictions_bnm)))\n",
    "print(\"Recall Score : \" + str(recall_score(y_test, training_predictions_bnm)))\n",
    "print(\"Confusion Matrix : \" + str(confusion_matrix(y_test, training_predictions_bnm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember those old kung fu movies we used to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is another one on my List of Movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How in the world does a thing like this get in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Queen of the Damned\" is one of the best vampi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Caprica episode (S01E01) is well done as a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I usually really enjoy Steven Seagal movies. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JiÃ¸Ã­ Trnka made his last animated short an i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is so bad it will be my contribution to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Watching this hilariously retro but very enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Excellent political thriller, played much quie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Remember those old kung fu movies we used to w...\n",
       "1  This movie is another one on my List of Movies...\n",
       "2  How in the world does a thing like this get in...\n",
       "3  \"Queen of the Damned\" is one of the best vampi...\n",
       "4  The Caprica episode (S01E01) is well done as a...\n",
       "5  I usually really enjoy Steven Seagal movies. T...\n",
       "6  JiÃ¸Ã­ Trnka made his last animated short an i...\n",
       "7  This is so bad it will be my contribution to t...\n",
       "8  Watching this hilariously retro but very enter...\n",
       "9  Excellent political thriller, played much quie..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Preprocessing\n",
    "def NLTK_preprocessing_testing(review):\n",
    "    \n",
    "    words = []\n",
    "    for i in range(review.shape[0]):\n",
    "        # 2 Tokenization using Regular Expression\n",
    "        words.append(tokenizer.tokenize(review[i]))\n",
    "\n",
    "    useful_words = []\n",
    "    # 3 Remove stopwords\n",
    "    for i in range(len(words)):\n",
    "        useful_text = [w for w in words[i] if w not in en_stopwords]\n",
    "        useful_words.append(useful_text)\n",
    "    \n",
    "    # 4 Stemming\n",
    "    for i in range(len(useful_words)):\n",
    "        for j in range(len(useful_words[i])):\n",
    "            # Stem the words\n",
    "            useful_words[i][j] = ps.stem(useful_words[i][j])\n",
    "\n",
    "    # Join the words\n",
    "    for i in range(len(useful_words)):\n",
    "        useful_words[i] = \" \".join(useful_words[i])\n",
    "    \n",
    "    return useful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_words = NLTK_preprocessing_testing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_vc = tfidf.transform(testing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64377)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_vc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "\n",
    "testing_predictions = mnb.predict(testing_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(arr):\n",
    "    \n",
    "    # Convert integer classes into strings\n",
    "    arr = arr.astype('str')\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        \n",
    "        if arr[i] == \"1\":\n",
    "            arr[i] = 'pos'\n",
    "        else:\n",
    "            arr[i] = 'neg'\n",
    "            \n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(arr, columns = ['label'])\n",
    "    df.index.name = 'Id'\n",
    "    \n",
    "    # Convert to csv\n",
    "    \n",
    "    final_submissions_1 = df.to_csv(r\"C:\\Users\\manch\\OneDrive\\Desktop\\Data Science Live Course\\Movie Rating using Naive Bayes\\Dataset\\final_submissions_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_csv(testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions_bnb = bnm.predict(testing_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_csv(testing_predictions_bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
